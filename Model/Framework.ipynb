{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yl7S-gKwCF1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wm_JdO1Vu4nR"
      },
      "source": [
        "## GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1zkMjUgAegY"
      },
      "source": [
        "### GPU info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GN0XPaF2AjzK",
        "outputId": "0727b1c0-65d2-47b8-dfa8-00d1184a6655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Feb 23 10:50:56 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPAbmQ4DANlg"
      },
      "source": [
        "## Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxZpG_QUANlg"
      },
      "source": [
        "### Lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42iXEetaANlg"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Util #\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "from scipy.sparse import linalg\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Layer #\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import numbers\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Model #\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import sys\n",
        "\n",
        "# Trainer #\n",
        "import torch.optim as optim\n",
        "import math\n",
        "\n",
        "# Main #\n",
        "import torch\n",
        "import numpy as np\n",
        "import argparse\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9m9BJMEvANlh"
      },
      "source": [
        "### Util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3lArIYWANlh"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DataLoaderM(object):\n",
        "    def __init__(self, xs, ys, batch_size, pad_with_last_sample=True):\n",
        "        \"\"\"\n",
        "        :param xs:\n",
        "        :param ys:\n",
        "        :param batch_size:\n",
        "        :param pad_with_last_sample: pad with the last sample to make number of samples divisible to batch_size.\n",
        "        \"\"\"\n",
        "        self.batch_size = batch_size\n",
        "        self.current_ind = 0\n",
        "\n",
        "        # 將資料長度補齊至batch_size可整除之數量\n",
        "        # 補齊方法: 取原資料最後一個並複製多個來補齊\n",
        "        if pad_with_last_sample:\n",
        "            # 計算需補齊數量\n",
        "            num_padding = (batch_size - (len(xs) % batch_size)) % batch_size\n",
        "            x_padding = np.repeat(xs[-1:], num_padding, axis=0)\n",
        "            y_padding = np.repeat(ys[-1:], num_padding, axis=0)\n",
        "\n",
        "            # 將複製後的ele進行concatenate以補齊成可整除batch_size之長度\n",
        "            xs = np.concatenate([xs, x_padding], axis=0)\n",
        "            ys = np.concatenate([ys, y_padding], axis=0)\n",
        "        self.size = len(xs)\n",
        "        self.num_batch = int(self.size // self.batch_size)\n",
        "        self.xs = xs\n",
        "        self.ys = ys\n",
        "\n",
        "    #**fusion**#\n",
        "    def set_permutation(self, permutation):\n",
        "        assert len(permutation) == self.size, \"Permutation length must match data size\"\n",
        "        self.xs = self.xs[permutation]\n",
        "        self.ys = self.ys[permutation]\n",
        "    '''\n",
        "    def shuffle(self):\n",
        "        permutation = np.random.permutation(self.size)\n",
        "        xs, ys = self.xs[permutation], self.ys[permutation]\n",
        "        self.xs = xs\n",
        "        self.ys = ys\n",
        "    '''\n",
        "\n",
        "    def get_iterator(self):\n",
        "        self.current_ind = 0\n",
        "        def _wrapper():\n",
        "            while self.current_ind < self.num_batch:\n",
        "                start_ind = self.batch_size * self.current_ind\n",
        "                end_ind = min(self.size, self.batch_size * (self.current_ind + 1))\n",
        "                x_i = self.xs[start_ind: end_ind, ...]\n",
        "                y_i = self.ys[start_ind: end_ind, ...]\n",
        "                # 節省記憶體:\n",
        "                # yield 設計來的目的，就是為了單次輸出內容\n",
        "                # 我們可以把 yield 暫時看成 return，但是這個 return 的功能只有單次\n",
        "                # 而且，一旦我們的程式執行到 yield 後，程式就會把值丟出，並暫時停止\n",
        "                yield (x_i, y_i)\n",
        "                self.current_ind += 1\n",
        "\n",
        "        return _wrapper()\n",
        "\n",
        "class StandardScaler():\n",
        "    \"\"\"\n",
        "    Standard the input\n",
        "    \"\"\"\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "    def transform(self, data):\n",
        "        return (data - self.mean) / self.std\n",
        "    def inverse_transform(self, data):\n",
        "        return (data * self.std) + self.mean\n",
        "\n",
        "def asym_adj(adj):\n",
        "    \"\"\"Asymmetrically normalize adjacency matrix.\"\"\"\n",
        "    adj = sp.coo_matrix(adj)\n",
        "    rowsum = np.array(adj.sum(1)).flatten()\n",
        "    d_inv = np.power(rowsum, -1).flatten()\n",
        "    d_inv[np.isinf(d_inv)] = 0.\n",
        "    d_mat= sp.diags(d_inv)\n",
        "    return d_mat.dot(adj).astype(np.float32).todense()\n",
        "\n",
        "\n",
        "def load_pickle(pickle_file):\n",
        "    try:\n",
        "        with open(pickle_file, 'rb') as f:\n",
        "            pickle_data = pickle.load(f)\n",
        "    except UnicodeDecodeError as e:\n",
        "        with open(pickle_file, 'rb') as f:\n",
        "            pickle_data = pickle.load(f, encoding='latin1')\n",
        "    except Exception as e:\n",
        "        print('Unable to load data ', pickle_file, ':', e)\n",
        "        raise\n",
        "    return pickle_data\n",
        "\n",
        "def load_adj(pkl_filename, adjtype):\n",
        "    sensor_ids, sensor_id_to_ind, adj_mx = load_pickle(pkl_filename)\n",
        "\n",
        "    print('# 全部L.A.的sensor ID(sensor_ids):\\n',sensor_ids)\n",
        "    print('# 將sensor ID對應index(sensor_id_to_ind):\\n',sensor_id_to_ind)\n",
        "\n",
        "    if adjtype == \"scalap\":\n",
        "        adj = [calculate_scaled_laplacian(adj_mx)]\n",
        "    elif adjtype == \"normlap\":\n",
        "        adj = [calculate_normalized_laplacian(adj_mx).astype(np.float32).todense()]\n",
        "    elif adjtype == \"symnadj\":\n",
        "        adj = [sym_adj(adj_mx)]\n",
        "    elif adjtype == \"transition\":\n",
        "        adj = [asym_adj(adj_mx)]\n",
        "    elif adjtype == \"doubletransition\":\n",
        "        adj = [asym_adj(adj_mx), asym_adj(np.transpose(adj_mx))]   # asym_adj(adj_mx): forward transition matrix / asym_adj(np.transpose(adj_mx)): backward transition matrix\n",
        "    elif adjtype == \"identity\":\n",
        "        adj = [np.diag(np.ones(adj_mx.shape[0])).astype(np.float32)]\n",
        "    else:\n",
        "        error = 0\n",
        "        assert error, \"adj type not defined\"\n",
        "\n",
        "    print('# Double transition Transition matrix of Eq 4:\\n',adj)\n",
        "    return sensor_ids, sensor_id_to_ind, adj\n",
        "\n",
        "\n",
        "def masked_mse(preds, labels, null_val=np.nan):\n",
        "    if np.isnan(null_val):\n",
        "        mask = ~torch.isnan(labels)\n",
        "    else:\n",
        "        mask = (labels!=null_val)\n",
        "    mask = mask.float()\n",
        "    mask /= torch.mean((mask))\n",
        "    mask = torch.where(torch.isnan(mask), torch.zeros_like(mask), mask)\n",
        "    loss = (preds-labels)**2\n",
        "    loss = loss * mask\n",
        "    loss = torch.where(torch.isnan(loss), torch.zeros_like(loss), loss)\n",
        "    return torch.mean(loss)\n",
        "\n",
        "def masked_rmse(preds, labels, null_val=np.nan):\n",
        "    return torch.sqrt(masked_mse(preds=preds, labels=labels, null_val=null_val))\n",
        "\n",
        "\n",
        "def masked_mae(preds, labels, null_val=np.nan):\n",
        "    if np.isnan(null_val):\n",
        "        mask = ~torch.isnan(labels)\n",
        "    else:\n",
        "        mask = (labels!=null_val)\n",
        "    mask = mask.float()\n",
        "    mask /=  torch.mean((mask))\n",
        "    mask = torch.where(torch.isnan(mask), torch.zeros_like(mask), mask)\n",
        "    loss = torch.abs(preds-labels)\n",
        "    loss = loss * mask\n",
        "    loss = torch.where(torch.isnan(loss), torch.zeros_like(loss), loss)\n",
        "    return torch.mean(loss)\n",
        "def masked_mape(preds, labels, null_val=np.nan):\n",
        "    if np.isnan(null_val):\n",
        "        mask = ~torch.isnan(labels)\n",
        "    else:\n",
        "        mask = (labels!=null_val)\n",
        "    mask = mask.float()\n",
        "    mask /=  torch.mean((mask))\n",
        "    mask = torch.where(torch.isnan(mask), torch.zeros_like(mask), mask)\n",
        "    loss = torch.abs(preds-labels)/labels\n",
        "    #loss = 2.0 * torch.mean(torch.abs(preds - labels) / (torch.abs(preds) + torch.abs(labels)))\n",
        "    loss = loss * mask\n",
        "    loss = torch.where(torch.isnan(loss), torch.zeros_like(loss), loss)\n",
        "    return torch.mean(loss)\n",
        "def masked_smape(preds, labels, null_val=np.nan):\n",
        "    if np.isnan(null_val):\n",
        "        mask = ~torch.isnan(labels)\n",
        "    else:\n",
        "        mask = (labels!=null_val)\n",
        "    mask = mask.float()\n",
        "    mask /=  torch.mean((mask))\n",
        "    mask = torch.where(torch.isnan(mask), torch.zeros_like(mask), mask)\n",
        "    #loss = torch.abs(preds-labels)/labels\n",
        "    loss = 2.0 * (torch.abs(preds - labels) / (torch.abs(preds) + torch.abs(labels)))\n",
        "    loss = loss * mask\n",
        "    loss = torch.where(torch.isnan(loss), torch.zeros_like(loss), loss)\n",
        "    return torch.mean(loss)\n",
        "\n",
        "def metric(pred, real):\n",
        "    mae = masked_mae(pred,real,0.0).item()\n",
        "    mape = masked_mape(pred,real,0.0).item()\n",
        "    rmse = masked_rmse(pred,real,0.0).item()\n",
        "    smape = masked_smape(pred,real,0.0).item()\n",
        "    return mae,mape,rmse,smape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4fdCQ3TANli"
      },
      "source": [
        "### Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8DYHAPCANli"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class linear(nn.Module):\n",
        "    def __init__(self,c_in,c_out,bias=True):\n",
        "        super(linear,self).__init__()\n",
        "        self.mlp = torch.nn.Conv2d(c_in, c_out, kernel_size=(1, 1), padding=(0,0), stride=(1,1), bias=bias)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.mlp(x)\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    __constants__ = ['normalized_shape', 'weight', 'bias', 'eps', 'elementwise_affine']\n",
        "    def __init__(self, normalized_shape, eps=1e-5, elementwise_affine=True):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        if isinstance(normalized_shape, numbers.Integral):\n",
        "            normalized_shape = (normalized_shape,)\n",
        "        self.normalized_shape = tuple(normalized_shape)\n",
        "        self.eps = eps\n",
        "        self.elementwise_affine = elementwise_affine\n",
        "        if self.elementwise_affine:\n",
        "            self.weight = nn.Parameter(torch.Tensor(*normalized_shape))\n",
        "            self.bias = nn.Parameter(torch.Tensor(*normalized_shape))\n",
        "        else:\n",
        "            self.register_parameter('weight', None)\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        if self.elementwise_affine:\n",
        "            init.ones_(self.weight)\n",
        "            init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, input, idx):\n",
        "        if self.elementwise_affine:\n",
        "            return F.layer_norm(input, tuple(input.shape[1:]), self.weight[:,idx,:], self.bias[:,idx,:], self.eps)\n",
        "        else:\n",
        "            return F.layer_norm(input, tuple(input.shape[1:]), self.weight, self.bias, self.eps)\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return '{normalized_shape}, eps={eps}, ' \\\n",
        "            'elementwise_affine={elementwise_affine}'.format(**self.__dict__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCXijts6VgTW"
      },
      "source": [
        "### MGAT (for Enhancement step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWBPDdtjVgTX"
      },
      "outputs": [],
      "source": [
        "\n",
        "class A_GMAT_base(nn.Module):\n",
        "    def __init__(self, n_heads, in_channel, num_nodes, dropout, bias=True):\n",
        "        super(A_GMAT_base, self).__init__()\n",
        "\n",
        "        print('A_GMAT_base', n_heads, in_channel, num_nodes, dropout)\n",
        "        self.n_head = n_heads\n",
        "        self.f_in = num_nodes\n",
        "        self.a_src = nn.Parameter(torch.Tensor(self.n_head, 10, 1))\n",
        "        self.a_dst = nn.Parameter(torch.Tensor(self.n_head, 10, 1))\n",
        "\n",
        "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.Tensor(10))\n",
        "            nn.init.constant_(self.bias, 0)\n",
        "        else:\n",
        "            self.register_parameter(\"bias\", None)\n",
        "\n",
        "        nn.init.xavier_uniform_(self.a_src, gain=1.414)\n",
        "        nn.init.xavier_uniform_(self.a_dst, gain=1.414)\n",
        "\n",
        "    def forward(self, h):\n",
        "        bs, ch, n, dim = h.size()\n",
        "        h_prime = h\n",
        "        attn_src = torch.matmul(h, self.a_src)\n",
        "        attn_dst = torch.matmul(h, self.a_dst)\n",
        "        attn = attn_src.expand(-1, -1, -1, n) + attn_dst.expand(-1, -1, -1, n).permute(\n",
        "            0, 1, 3, 2\n",
        "        )\n",
        "        attn = self.leaky_relu(attn)\n",
        "        attn = self.softmax(attn)\n",
        "        attn = self.dropout(attn)\n",
        "        output = torch.matmul(attn, h_prime)\n",
        "        return output + self.bias, attn\n",
        "\n",
        "class A_GMAT(nn.Module):\n",
        "    def __init__(self, n_heads, in_channel, num_nodes, dropout, alpha):\n",
        "        super(A_GMAT, self).__init__()\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.layer = A_GMAT_base(\n",
        "                    n_heads, in_channel, num_nodes, dropout\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        bs,ch,n,dim = x.size()\n",
        "        x, attn = self.layer(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class A_GMAT_module(nn.Module):\n",
        "    def __init__(self, n_heads, in_channel, num_nodes, mlp, mlp2, dropout, alpha):\n",
        "        super(A_GMAT_module, self).__init__()\n",
        "        print('A_GMAT_module', n_heads, in_channel, num_nodes, dropout, alpha)\n",
        "        self.net = A_GMAT(n_heads, in_channel, num_nodes, dropout, alpha)\n",
        "\n",
        "        self.mlp_convs = nn.ModuleList()\n",
        "        self.mlp_bns = nn.ModuleList()\n",
        "        last_channel = 32\n",
        "        for out_channel in mlp:\n",
        "            self.mlp_convs.append(nn.Conv2d(last_channel, out_channel, 1))\n",
        "            last_channel = out_channel\n",
        "\n",
        "        self.mlp_convs2 = nn.ModuleList()\n",
        "        self.mlp_bns2 = nn.ModuleList()\n",
        "        last_channel = n_heads\n",
        "        for out_channel in mlp2:\n",
        "            self.mlp_convs2.append(nn.Conv2d(last_channel, out_channel, 1))\n",
        "            last_channel = out_channel\n",
        "\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "        self.dropout2 = nn.Dropout(0.6)\n",
        "    def forward(self,x):\n",
        "        #print('in MGAT x.shape',x.shape)\n",
        "        #sys.exit()\n",
        "        bs, ch, n, dim = x.size()\n",
        "\n",
        "        x_input = x\n",
        "\n",
        "        x_all = []\n",
        "        x_input_cpy = x_input\n",
        "\n",
        "        for i, conv in enumerate(self.mlp_convs):\n",
        "          x_input = ((conv(x_input)))\n",
        "\n",
        "        x_input_cpy2 = x_input\n",
        "        x_input = self.net(x_input)\n",
        "        x_input = x_input_cpy2+ self.dropout1(x_input)\n",
        "\n",
        "        for i, conv in enumerate(self.mlp_convs2):\n",
        "          x_input = F.relu((conv(x_input)))\n",
        "\n",
        "        x_input = x_input_cpy+ self.dropout2(x_input)\n",
        "\n",
        "        return x_input\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v1XVDNqlJzz"
      },
      "source": [
        "### STGNN's architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8D1cMi41lMGF"
      },
      "outputs": [],
      "source": [
        "\n",
        "# this efficient implementation comes from https://github.com/xptree/DeepInf/\n",
        "class BatchMultiHeadGraphAttention(nn.Module):\n",
        "    def __init__(self, n_heads, in_channel, num_nodes, dropout, bias=True):\n",
        "        super(BatchMultiHeadGraphAttention, self).__init__()\n",
        "\n",
        "        print('BatchMultiHeadGraphAttention', n_heads, in_channel, num_nodes, dropout)\n",
        "        self.n_head = n_heads\n",
        "        self.f_in = num_nodes\n",
        "        #self.w = nn.Parameter(torch.Tensor(self.n_head, num_nodes, num_nodes))\n",
        "        self.a_src = nn.Parameter(torch.Tensor(self.n_head, num_nodes, 1))\n",
        "        self.a_dst = nn.Parameter(torch.Tensor(self.n_head, num_nodes, 1))\n",
        "\n",
        "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.Tensor(num_nodes))\n",
        "            nn.init.constant_(self.bias, 0)\n",
        "        else:\n",
        "            self.register_parameter(\"bias\", None)\n",
        "\n",
        "        #nn.init.xavier_uniform_(self.w, gain=1.414)\n",
        "        nn.init.xavier_uniform_(self.a_src, gain=1.414)\n",
        "        nn.init.xavier_uniform_(self.a_dst, gain=1.414)\n",
        "\n",
        "    def forward(self, h):\n",
        "        bs, ch, n, dim = h.size()\n",
        "        #h_prime = torch.matmul(h, self.w)\n",
        "        h_prime = h\n",
        "        attn_src = torch.matmul(h, self.a_src)\n",
        "        attn_dst = torch.matmul(h, self.a_dst)\n",
        "        attn = attn_src.expand(-1, -1, -1, n) + attn_dst.expand(-1, -1, -1, n).permute(\n",
        "            0, 1, 3, 2\n",
        "        )\n",
        "\n",
        "        '''\n",
        "        ##############\n",
        "        '''\n",
        "\n",
        "        attn = self.leaky_relu(attn)\n",
        "        attn = self.softmax(attn)\n",
        "        attn = self.dropout(attn)\n",
        "        output = torch.matmul(attn, h_prime)\n",
        "        return output + self.bias, attn\n",
        "\n",
        "class GAT(nn.Module):\n",
        "    def __init__(self, n_heads, in_channel, num_nodes, dropout, alpha):\n",
        "        super(GAT, self).__init__()\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.gat_layer = BatchMultiHeadGraphAttention(\n",
        "                    n_heads, in_channel, num_nodes, dropout\n",
        "                )\n",
        "\n",
        "        #self.norm = torch.nn.InstanceNorm2d(32).cuda()\n",
        "\n",
        "    def forward(self, x):\n",
        "        bs,ch,n,dim = x.size()\n",
        "        #x = self.norm(x) # instance norm for 32 channel\n",
        "        x, attn = self.gat_layer(x)\n",
        "        #x = F.elu(x.transpose(1, 2).contiguous().view(bs, ch, n, -1))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class GATEncoder(nn.Module):\n",
        "    def __init__(self, kern, dilation_factor, temporal_len, n_heads, in_channel, num_nodes, mlp, mlp2, dropout, alpha):\n",
        "        super(GATEncoder, self).__init__()\n",
        "\n",
        "        print('GATEncoder', n_heads, in_channel, num_nodes, dropout, alpha)\n",
        "        self.gat_net = GAT(n_heads, in_channel, num_nodes, dropout, alpha)\n",
        "\n",
        "        self.mlp_convs = nn.ModuleList()\n",
        "        self.mlp_bns = nn.ModuleList()\n",
        "        last_channel = 32\n",
        "        for out_channel in mlp:\n",
        "            self.mlp_convs.append(nn.Conv2d(last_channel, out_channel, 1))\n",
        "            last_channel = out_channel\n",
        "\n",
        "        self.mlp_convs2 = nn.ModuleList()\n",
        "        self.mlp_bns2 = nn.ModuleList()\n",
        "        last_channel = n_heads\n",
        "        print('mlp2', mlp2)\n",
        "        for out_channel in mlp2:\n",
        "            self.mlp_convs2.append(nn.Conv2d(last_channel, out_channel, 1))\n",
        "            last_channel = out_channel\n",
        "\n",
        "        #self.lay_norm = nn.LayerNorm([32, temporal_len, num_nodes])\n",
        "        #self.lay_norm2 = nn.LayerNorm([n_heads,temporal_len, num_nodes])\n",
        "\n",
        "        #self.bn_norm1 = nn.BatchNorm2d(8)\n",
        "        self.bn_norm2 = nn.BatchNorm2d(out_channel)\n",
        "        self.bn_norm3 = nn.BatchNorm2d(out_channel)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "        self.mlp = (nn.Conv2d(32,32,(1,kern),dilation=(1,dilation_factor)))\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        bs, ch, n, dim = x.size()\n",
        "\n",
        "        x_input = x.permute(0,1,3,2)\n",
        "        x_input_cpy = x_input\n",
        "\n",
        "        #-------------relu(CNN)-------------#\n",
        "        for i, conv in enumerate(self.mlp_convs):\n",
        "            #print('1x_input in', x_input.shape)\n",
        "            x_input = F.relu((conv(x_input)))\n",
        "            #print('1x_input out', x_input.shape)\n",
        "        #-------------relu(CNN)-------------#\n",
        "\n",
        "        #-------------GAT-------------#\n",
        "        x_input_cpy2 = x_input\n",
        "\n",
        "        x_input = self.gat_net(x_input)\n",
        "\n",
        "        x_input = x_input_cpy2+ self.dropout1(x_input)\n",
        "        #-------------GAT-------------#\n",
        "\n",
        "        #print('x_input1', x_input.shape)\n",
        "        #-------------relu(CNN)-------------#\n",
        "        for i, conv in enumerate(self.mlp_convs2):\n",
        "          #print('x_input in', x_input.shape)\n",
        "          x_input = F.relu((conv(x_input)))\n",
        "          #print('x_input out', x_input.shape)\n",
        "        #-------------relu(CNN)-------------#\n",
        "        #print('x_input', x_input.shape)\n",
        "        x_input = (x_input_cpy + self.dropout2(x_input)).permute(0,1,3,2)\n",
        "\n",
        "        x_input = self.bn_norm2(x_input)\n",
        "\n",
        "        #最後一維度緊收\n",
        "        x_input = F.relu(self.mlp(x_input))\n",
        "        x_input = self.bn_norm3(x_input)\n",
        "\n",
        "        return x_input\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def create_matrix(n, k):\n",
        "    mat = np.zeros((n, n))\n",
        "    for i in range(n):\n",
        "        for j in range(k):\n",
        "            if i-j >= 0:\n",
        "                mat[i][i-j] = 1\n",
        "    return mat\n",
        "\n",
        "\n",
        "def pearson_corr2(tensor): # all: (64,1,n,dim)\n",
        "  # Input tensor shape: (batch_size, num_nodes, time_steps)\n",
        "  batch_size, num_nodes, _ = tensor.shape\n",
        "  tensor = tensor - tensor.mean(dim=2, keepdim=True)\n",
        "  std = tensor.std(dim=2, keepdim=True)\n",
        "  tensor = tensor / (std + 1e-8)\n",
        "  correlation_matrix = torch.matmul(tensor, tensor.transpose(1, 2))\n",
        "  correlation_matrix = correlation_matrix / (tensor.shape[2] - 1)\n",
        "  return correlation_matrix\n",
        "\n",
        "\n",
        "def topK(attn, top_num ):\n",
        "\n",
        "  # Get the top K values and their indices for each row\n",
        "  top_k_values, top_k_indices = attn.topk(top_num, dim=3)\n",
        "\n",
        "  # Create a mask with the same shape as the input tensor, filled with zeros\n",
        "  mask = torch.zeros_like(attn)\n",
        "\n",
        "  # Set the top K values in the mask to 1\n",
        "  mask.scatter_(3, top_k_indices, 1)\n",
        "\n",
        "  # Multiply the input tensor with the mask to get the result\n",
        "  attn = attn * mask\n",
        "\n",
        "  return  attn\n",
        "\n",
        "\n",
        "\n",
        "# this efficient implementation comes from https://github.com/xptree/DeepInf/\n",
        "class S_BatchMultiHeadGraphAttention(nn.Module):\n",
        "    def __init__(self, n_heads, num_nodes, dropout, bias=True):\n",
        "        super(S_BatchMultiHeadGraphAttention, self).__init__()\n",
        "\n",
        "        print('S_BatchMultiHeadGraphAttention', n_heads, num_nodes, dropout)\n",
        "        self.n_head = n_heads\n",
        "        self.f_in = num_nodes\n",
        "        #self.w = nn.Parameter(torch.Tensor(self.n_head, num_nodes, num_nodes))\n",
        "        self.a_src = nn.Parameter(torch.Tensor(self.n_head*2, num_nodes, 1))\n",
        "        self.a_dst = nn.Parameter(torch.Tensor(self.n_head*2, num_nodes, 1))\n",
        "\n",
        "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.Tensor(num_nodes))\n",
        "            nn.init.constant_(self.bias, 0)\n",
        "        else:\n",
        "            self.register_parameter(\"bias\", None)\n",
        "\n",
        "\n",
        "        nn.init.xavier_uniform_(self.a_src, gain=1.414)\n",
        "        nn.init.xavier_uniform_(self.a_dst, gain=1.414)\n",
        "\n",
        "        self.W_si = nn.Parameter(torch.zeros(size=(1, 1)))\n",
        "        nn.init.xavier_uniform_(self.W_si.data, gain=1.414)\n",
        "        self.W_ei = nn.Parameter(torch.zeros(size=(1, 1)))\n",
        "        nn.init.xavier_uniform_(self.W_ei.data, gain=1.414)\n",
        "\n",
        "    def forward(self, h, a):\n",
        "\n",
        "        bs, ch, n, dim = h.size()\n",
        "        #h_prime = torch.matmul(h, self.w)\n",
        "        h_prime = h\n",
        "        attn_src = torch.matmul(torch.tanh(h), self.a_src)\n",
        "        attn_dst = torch.matmul(torch.tanh(h), self.a_dst)\n",
        "        attn = attn_src.expand(-1, -1, -1, n) + attn_dst.expand(-1, -1, -1, n).permute(\n",
        "            0, 1, 3, 2\n",
        "        )\n",
        "\n",
        "        attn_2 = self.leaky_relu(attn)\n",
        "        attn_2 = self.softmax(attn_2)\n",
        "        attn_2 = self.dropout(attn_2)\n",
        "\n",
        "        attn_2 = abs(self.W_ei)*attn_2+abs(self.W_si)*a\n",
        "\n",
        "        output_2 = torch.matmul(attn_2, h_prime)\n",
        "\n",
        "        return output_2, attn\n",
        "\n",
        "# MutiChannel_GAT(kern, dilation_factor, n_heads, num_nodes, mlp, mlp2, dropout)\n",
        "class S_MutiChannel_GAT(nn.Module):\n",
        "    def __init__(self, kern, dilation_factor, n_heads, num_nodes, mlp, mlp2, dropout):\n",
        "        super(S_MutiChannel_GAT, self).__init__()\n",
        "\n",
        "        print('S_MutiChannel_GAT', n_heads, num_nodes, dropout)\n",
        "\n",
        "        self.gat_layer = S_BatchMultiHeadGraphAttention(\n",
        "            n_heads, num_nodes, dropout\n",
        "        )\n",
        "        self.gat_layer2 = S_BatchMultiHeadGraphAttention(\n",
        "            n_heads, num_nodes, dropout\n",
        "        )\n",
        "\n",
        "        self.mlp1 =  nn.Conv2d(in_channels=32,\n",
        "                                    out_channels=16,\n",
        "                                    kernel_size=(1, 1))\n",
        "\n",
        "        self.mlp2 =  nn.Conv2d(in_channels=48,\n",
        "                                    out_channels=32,\n",
        "                                    kernel_size=(1, 1))\n",
        "\n",
        "    def forward(self,x_input, a_f):\n",
        "        x_input_cpy = x_input\n",
        "\n",
        "        x = x_input\n",
        "        x = self.mlp1(x)\n",
        "\n",
        "        x1, attn = self.gat_layer(x,a_f)\n",
        "        a_f = torch.matmul(a_f,a_f)\n",
        "        x2, attn = self.gat_layer2(x1,a_f)\n",
        "\n",
        "        x_out = self.mlp2(torch.cat([x,x1,x2],dim=1))\n",
        "\n",
        "        return x_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Din7SfGgJ_F3"
      },
      "source": [
        "### Framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dNFcy8fJ_F3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class gginet(nn.Module):\n",
        "    def __init__(self, model_type,  num_nodes, device, predefined_A=None,kernel_set=None, static_feat=None, dropout=0.3, node_dim=40, dilation_exponential=1, conv_channels=32, residual_channels=32, skip_channels=64, end_channels=128, seq_length=12, in_dim=2, out_dim=12, layers=3, propalpha=0.05, tanhalpha=3, layer_norm_affline=True):\n",
        "        super(gginet, self).__init__()\n",
        "\n",
        "        self.model_type = model_type\n",
        "\n",
        "        self.num_nodes = num_nodes\n",
        "        self.dropout = dropout\n",
        "        self.predefined_A = predefined_A\n",
        "        self.layers = layers\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "        self.t_gat1 = nn.ModuleList()\n",
        "        self.t_gat2 = nn.ModuleList()\n",
        "\n",
        "        self.residual_convs = nn.ModuleList()\n",
        "        self.skip_convs = nn.ModuleList()\n",
        "        self.s_gat = nn.ModuleList()\n",
        "        self.norm = nn.ModuleList()\n",
        "        self.start_conv = nn.Conv2d(in_channels=in_dim,\n",
        "                                    out_channels=residual_channels,\n",
        "                                    kernel_size=(1, 1))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if self.model_type == \"GMAT\":\n",
        "            # Paepr eq 11: R=1+(c-1)(q^m -1)/(q -1).\n",
        "            kernel_size = 7\n",
        "            if dilation_exponential>1:\n",
        "                self.receptive_field = int(1+(kernel_size-1)*(dilation_exponential**layers-1)/(dilation_exponential-1))\n",
        "            else:\n",
        "                self.receptive_field = layers*(kernel_size-1) + 1\n",
        "\n",
        "        print(\"# Model Type\", self.model_type)\n",
        "        print(\"# receptive_field\", self.receptive_field)\n",
        "        i=0\n",
        "        if dilation_exponential>1:\n",
        "            rf_size_i = int(1 + i*(kernel_size-1)*(dilation_exponential**layers-1)/(dilation_exponential-1))\n",
        "        else:\n",
        "            rf_size_i = i*layers*(kernel_size-1)+1\n",
        "        new_dilation = 1\n",
        "\n",
        "        self.receptive_field = 10\n",
        "        target_len = self.receptive_field\n",
        "\n",
        "\n",
        "        self.t_len = []\n",
        "        for j in range(1,layers+1):\n",
        "\n",
        "\n",
        "            if self.model_type == \"GMAT\":\n",
        "                if dilation_exponential > 1:\n",
        "                    rf_size_j = int(rf_size_i + (kernel_size-1)*(dilation_exponential**j-1)/(dilation_exponential-1))\n",
        "                else:\n",
        "                    rf_size_j = rf_size_i+j*(kernel_size-1)\n",
        "\n",
        "            if j % 2 == 1:\n",
        "                new_dilation = 1\n",
        "            elif j % 2 == 0:\n",
        "                new_dilation = 2\n",
        "            dilation_factor = new_dilation\n",
        "            kern = 2\n",
        "\n",
        "            in_channel = 32\n",
        "            n_heads = 8\n",
        "            dropout = 0\n",
        "            alpha = 0.2\n",
        "            self.t_gat1.append(\n",
        "                GATEncoder(\n",
        "                  kern= kern, dilation_factor=dilation_factor, temporal_len = target_len, n_heads=n_heads, in_channel= in_channel, num_nodes=num_nodes, mlp=[16,n_heads],mlp2=[16,32], dropout=dropout, alpha=alpha\n",
        "                )\n",
        "            )\n",
        "\n",
        "            self.t_gat2.append(\n",
        "                GATEncoder(\n",
        "                  kern= kern, dilation_factor=dilation_factor, temporal_len = target_len, n_heads=n_heads, in_channel= in_channel, num_nodes=num_nodes, mlp=[16,n_heads],mlp2=[16,32], dropout=dropout, alpha=alpha\n",
        "                )\n",
        "            )\n",
        "\n",
        "            target_len -= dilation_factor\n",
        "            self.t_len.append(target_len)\n",
        "\n",
        "            if self.model_type == \"GMAT\" :\n",
        "                '''\n",
        "                # skip_convs #\n",
        "                (0): Conv2d(32, 64, kernel_size=(1, 13), stride=(1, 1))\n",
        "                (1): Conv2d(32, 64, kernel_size=(1, 7), stride=(1, 1))\n",
        "                (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "                '''\n",
        "                if self.seq_length>self.receptive_field:\n",
        "                    self.skip_convs.append(nn.Conv2d(in_channels=conv_channels,\n",
        "                                                    out_channels=skip_channels,\n",
        "                                                    kernel_size=(1, target_len)))\n",
        "                else:\n",
        "                    self.skip_convs.append(nn.Conv2d(in_channels=conv_channels,\n",
        "                                                    out_channels=skip_channels,\n",
        "                                                    kernel_size=(1, target_len)))\n",
        "            dilation_factor = 1\n",
        "            n_heads = 8\n",
        "\n",
        "            self.s_gat.append(S_MutiChannel_GAT(kern, dilation_factor, n_heads, target_len, [24,16,8], [16,24,32], dropout))\n",
        "\n",
        "            #####   GCN   ##### END\n",
        "\n",
        "            #####   Normalization   ##### START\n",
        "            if self.model_type == \"GMAT\":\n",
        "                if self.seq_length>self.receptive_field:\n",
        "                    print('1', self.seq_length - rf_size_j + 1)\n",
        "                    self.norm.append(LayerNorm((residual_channels, num_nodes, target_len),elementwise_affine=layer_norm_affline))\n",
        "                else:\n",
        "                    print('2', self.receptive_field - rf_size_j + 1)\n",
        "                    self.norm.append(LayerNorm((residual_channels, num_nodes, target_len),elementwise_affine=layer_norm_affline))\n",
        "            #####   Normalization   ##### END\n",
        "\n",
        "            new_dilation *= dilation_exponential\n",
        "\n",
        "\n",
        "\n",
        "        self.end_conv_1 = nn.Conv2d(in_channels=skip_channels,\n",
        "                                             out_channels=end_channels,\n",
        "                                             kernel_size=(1,1),\n",
        "                                             bias=True)\n",
        "        self.end_conv_2 = nn.Conv2d(in_channels=end_channels,\n",
        "                                             out_channels=out_dim,\n",
        "                                             kernel_size=(1,1),\n",
        "                                             bias=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #####   SKIP layer   ##### START\n",
        "        if self.model_type == \"GMAT\":\n",
        "            '''\n",
        "            (skip0): Conv2d(2, 64, kernel_size=(1, 19), stride=(1, 1))\n",
        "            (skipE): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "            '''\n",
        "            if self.seq_length > self.receptive_field:\n",
        "                self.skip0 = nn.Conv2d(in_channels=in_dim, out_channels=skip_channels, kernel_size=(1, self.seq_length), bias=True)\n",
        "                self.skipE = nn.Conv2d(in_channels=residual_channels, out_channels=skip_channels, kernel_size=(1, self.seq_length-self.receptive_field+1), bias=True)\n",
        "\n",
        "            else:\n",
        "                self.skip0 = nn.Conv2d(in_channels=in_dim, out_channels=skip_channels, kernel_size=(1, self.receptive_field), bias=True)\n",
        "                self.skipE = nn.Conv2d(in_channels=residual_channels, out_channels=skip_channels, kernel_size=(1, 1), bias=True)\n",
        "        #####   SKIP layer   ##### END\n",
        "\n",
        "        self.idx = torch.arange(self.num_nodes).to(device)\n",
        "\n",
        "\n",
        "    def forward(self, input, idx=None):\n",
        "        seq_len = input.size(3)\n",
        "\n",
        "        #**fusion**#\n",
        "        #assert seq_len==self.seq_length, 'input sequence length not equal to preset sequence length'\n",
        "        if hasattr(self, 'a_gmat_list'): # 代表有fusion\n",
        "          #print(\"in pretrain!!!!!!!!!!!!\")\n",
        "          self.seq_length = input.shape[3] # 讓(...,4)補成(...,10)跟原本ST對齊\n",
        "\n",
        "\n",
        "        # Step0: 檢查receptive_field, 不足則padding0\n",
        "        if self.seq_length<self.receptive_field:\n",
        "            input = nn.functional.pad(input,(self.receptive_field-self.seq_length,0,0,0))\n",
        "\n",
        "        #print('input2', input.shape, 'self.seq_length', self.seq_length)\n",
        "\n",
        "        # Step1: turn([64, 2, 207, 19]) to ([64, 32, 207, 19])\n",
        "        x = self.start_conv(input)\n",
        "\n",
        "        #**fusion**#\n",
        "        if hasattr(self, 'a_gmat_list'): # 代表有fusion\n",
        "          skip = 0\n",
        "\n",
        "          x_all = []\n",
        "          for i in range(len(adj_edges)):\n",
        "              target_node = F.elu(self.test_conv_1(x[:,:,i].unsqueeze(2)))\n",
        "\n",
        "              for out in outgoing[i]:\n",
        "                  outgoing_nodes = F.elu(self.test_conv_1(x[:,:, out].unsqueeze(2)))\n",
        "                  outgoing_nodes_representations = F.elu(self.test_conv_2(outgoing_nodes-target_node))\n",
        "                  #print('outgoing_nodes_representations', outgoing_nodes_representations.shape)\n",
        "\n",
        "                  ingoing_nodes = F.elu(self.test_conv_1(x[:,:, ingoing[i]]))\n",
        "                  intgoing_nodes_representations = F.elu(self.test_conv_3(target_node-ingoing_nodes))\n",
        "                  #print('intgoing_nodes_representations', intgoing_nodes_representations.shape)\n",
        "\n",
        "\n",
        "                  outgoing_nodes_representations = ((outgoing_nodes_representations))\n",
        "                  intgoing_nodes_representations = ((intgoing_nodes_representations))\n",
        "\n",
        "\n",
        "                  tmp_x = torch.cat([outgoing_nodes_representations,intgoing_nodes_representations],dim=2)\n",
        "\n",
        "                  tmp_x = self.a_gmat_list[0](tmp_x)\n",
        "                  x_all.append(tmp_x[:,:,0].unsqueeze(2))\n",
        "          x = torch.cat(x_all, dim=2)\n",
        "\n",
        "        else:\n",
        "          skip = self.skip0(F.dropout(input, self.dropout, training=self.training))\n",
        "\n",
        "\n",
        "        #    -- START #\n",
        "        # Layers : 3層 : 19->13->7->1 (取決於TCN取的維度)\n",
        "        for i in range(self.layers):\n",
        "\n",
        "            # Step2: Temporal Model --START #\n",
        "            # 為上一層輸出, ex:  [64, 32, 207, 19] -> [64, 32, 207, 13] -> [64, 32, 207, 7]-> [64, 32, 207, 1]\n",
        "            residual = x\n",
        "\n",
        "            #x = x.permute(0,1,3,2)\n",
        "\n",
        "            filter = self.t_gat1[i](x)\n",
        "            filter = torch.tanh(filter)\n",
        "\n",
        "            gate = self.t_gat2[i](x)\n",
        "            gate = torch.sigmoid(gate)\n",
        "\n",
        "            x = filter * gate\n",
        "            if self.model_type == \"GMAT\":\n",
        "                x = F.dropout(x, self.dropout, training=self.training)\n",
        "            # Step2: Temporal Model --END #\n",
        "\n",
        "            # Step3: Skip after TCN --START #\n",
        "            s = x\n",
        "\n",
        "            # fusion output:([64, 32, 207, 13])\n",
        "            # skip_convsL 0:([64, 64, 207, 1])\n",
        "            s = self.skip_convs[i](s)\n",
        "\n",
        "\n",
        "            skip = s + skip\n",
        "\n",
        "            # Step3: Skip after TCN --END #\n",
        "\n",
        "            x = self.s_gat[i](x, self.predefined_A[0])\n",
        "\n",
        "            # x 經過dilated處理後, 會減少feature維度, ex: 19->13->7->1\n",
        "            # 而residual為上一層輸出, 維度為: 19, 13 ...\n",
        "            # 所以需要配合x進行維度調整: [:, :, :, -x.size(3):], 然後進行elemenet-wise相加\n",
        "            x = x + residual[:, :, :, -x.size(3):]\n",
        "\n",
        "            if self.model_type == \"GMAT\":\n",
        "                if idx is None:\n",
        "                    x = self.norm[i](x,self.idx)\n",
        "                else:\n",
        "                    x = self.norm[i](x,idx)\n",
        "            # Step4: GCN --END #\n",
        "\n",
        "        #    -- END #\n",
        "\n",
        "        if self.model_type == \"GMAT\":\n",
        "            #(skipE): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "            skip = self.skipE(x) + skip\n",
        "\n",
        "        #sys.exit()\n",
        "        x = F.relu(skip)\n",
        "        x = F.relu(self.end_conv_1(x))\n",
        "        x = self.end_conv_2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbowdbREANli"
      },
      "source": [
        "### Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTga9hrXANli"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "    def __init__(self, model, lrate, wdecay, clip, step_size, seq_out_len, scaler, device, cl=True):\n",
        "        self.scaler = scaler\n",
        "\n",
        "        #**fusion**#\n",
        "        model.a_gmat_list = nn.ModuleList()\n",
        "        in_channel = 32\n",
        "        n_heads = 8\n",
        "        dropout = 0\n",
        "        alpha = 0.2\n",
        "        t_len = -1\n",
        "        model.a_gmat_list.append(\n",
        "            A_GMAT_module(\n",
        "              n_heads=n_heads, in_channel= in_channel, num_nodes=t_len, mlp=[n_heads],mlp2=[32], dropout=dropout, alpha=alpha\n",
        "            )\n",
        "        )\n",
        "\n",
        "        model.test_conv_1 = nn.Conv2d(in_channels=32,\n",
        "                                             out_channels=32,\n",
        "                                             kernel_size=(1,1),\n",
        "                                             bias=True)\n",
        "        model.test_conv_2 = nn.Conv2d(in_channels=32,\n",
        "                                             out_channels=32,\n",
        "                                             kernel_size=(1,1),\n",
        "                                             bias=True)\n",
        "        model.test_conv_3 = nn.Conv2d(in_channels=32,\n",
        "                                             out_channels=32,\n",
        "                                             kernel_size=(1,1),\n",
        "                                             bias=True)\n",
        "\n",
        "        self.model = model\n",
        "        self.model.to(device)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=lrate, weight_decay=wdecay)\n",
        "        self.loss = masked_mae\n",
        "        self.clip = clip\n",
        "        self.step = step_size\n",
        "        self.iter = 1\n",
        "        self.task_level = 1\n",
        "        self.seq_out_len = seq_out_len\n",
        "        self.cl = cl\n",
        "\n",
        "\n",
        "\n",
        "    def train(self, input, real_val, idx=None):\n",
        "        self.model.train()\n",
        "        self.optimizer.zero_grad()\n",
        "        output = self.model(input, idx=idx)\n",
        "        output = output.transpose(1,3)\n",
        "        real = torch.unsqueeze(real_val,dim=1)\n",
        "\n",
        "        predict = self.scaler.inverse_transform(output)\n",
        "\n",
        "        if self.iter%self.step==0 and self.task_level<=self.seq_out_len:\n",
        "            self.task_level +=1\n",
        "            print(\"### cl learning\\n iter\",self.iter,\"\\niter%step\",self.iter%self.step,\"\\ntask_level\",self.task_level)\n",
        "            print(\"# predict len:\", len(predict[:, :, :, :self.task_level]))\n",
        "\n",
        "        if self.cl:\n",
        "            loss = masked_mae(predict[:, :, :, :self.task_level], real[:, :, :, :self.task_level], 0.0)\n",
        "        else:\n",
        "            loss = masked_mae(predict, real, 0.0)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        if self.clip is not None:\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip)\n",
        "\n",
        "        self.optimizer.step()\n",
        "        mae = masked_mae(predict,real,0.0).item()\n",
        "        mape = masked_mape(predict,real,0.0).item()\n",
        "        rmse = masked_rmse(predict,real,0.0).item()\n",
        "        smape = masked_smape(predict,real,0.0).item()\n",
        "        self.iter += 1\n",
        "        return mae,mape,rmse,smape\n",
        "\n",
        "    def eval(self, input, real_val):\n",
        "        self.model.eval()\n",
        "        output = self.model(input)\n",
        "        output = output.transpose(1,3)\n",
        "        real = torch.unsqueeze(real_val,dim=1)\n",
        "\n",
        "        predict = self.scaler.inverse_transform(output)\n",
        "\n",
        "        loss = self.loss(predict, real, 0.0)\n",
        "        mape = masked_mape(predict,real,0.0).item()\n",
        "        rmse = masked_rmse(predict,real,0.0).item()\n",
        "        smape = masked_smape(predict,real,0.0).item()\n",
        "        return loss.item(),mape,rmse,smape\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_84y8rqsANlj"
      },
      "source": [
        "### Parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQX_bh_FANlj"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def str_to_bool(value):\n",
        "    if isinstance(value, bool):\n",
        "        return value\n",
        "    if value.lower() in {'false', 'f', '0', 'no', 'n'}:\n",
        "        return False\n",
        "    elif value.lower() in {'true', 't', '1', 'yes', 'y'}:\n",
        "        return True\n",
        "    raise ValueError(f'{value} is not a valid boolean value')\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--device',type=str,default='cuda',help='')\n",
        "parser.add_argument('--adjtype',type=str,default='doubletransition',help='adj type')\n",
        "\n",
        "parser.add_argument('--cl', type=str_to_bool, default=True,help='whether to do curriculum learning')\n",
        "\n",
        "parser.add_argument('--dropout',type=float,default=0.3,help='dropout rate')\n",
        "\n",
        "parser.add_argument('--node_dim',type=int,default=40,help='dim of nodes')\n",
        "parser.add_argument('--dilation_exponential',type=int,default=1,help='dilation exponential')\n",
        "\n",
        "parser.add_argument('--conv_channels',type=int,default=32,help='convolution channels')\n",
        "parser.add_argument('--residual_channels',type=int,default=32,help='residual channels')\n",
        "\n",
        "parser.add_argument('--in_dim',type=int,default=2,help='inputs dimension')\n",
        "\n",
        "parser.add_argument('--batch_size',type=int,default=64,help='batch size')\n",
        "parser.add_argument('--clip',type=int,default=5,help='clip')\n",
        "\n",
        "parser.add_argument('--model_type',type=str,default='GMAT',help='model type')\n",
        "parser.add_argument('--skip_channels',type=int,default=64,help='skip channels')\n",
        "parser.add_argument('--end_channels',type=int,default=128,help='end channels')\n",
        "\n",
        "parser.add_argument('--kernel_set',default=[2,3,6,7], type=int, nargs='+')\n",
        "\n",
        "\n",
        "parser.add_argument('--print_every',type=int,default=50,help='')\n",
        "parser.add_argument('--seed',type=int,default=101,help='random seed')\n",
        "parser.add_argument('--save',type=str,default='./save/',help='save path')\n",
        "\n",
        "parser.add_argument('--log_print', type=str_to_bool, default=False ,help='whether to load static feature')\n",
        "\n",
        "parser.add_argument('--learning_rate',type=float,default=0.0005,help='learning rate')\n",
        "parser.add_argument('--weight_decay',type=float,default=0.0001,help='weight decay rate')\n",
        "\n",
        "parser.add_argument('--step_size1',type=int,default=300,help='step_size')\n",
        "parser.add_argument('--step_size2',type=int,default=100,help='step_size')\n",
        "\n",
        "\n",
        "#**fusion**#\n",
        "# 把原本數值設為mobility\n",
        "target = 'Mobility_Flows'\n",
        "parser.add_argument('--data',type=str,default='../Data/'+target ,help='data path')\n",
        "parser.add_argument('--adj_data',type=str,default='../Data/'+target+'/adj_mat_input.pkl',help='adj data path')\n",
        "parser.add_argument('--num_nodes',type=int,default=84,help='number of nodes/variables')\n",
        "\n",
        "#**fusion**#\n",
        "# 用在pre-trained model 設定\n",
        "target = 'GCT_Flows'\n",
        "parser.add_argument('--data_pre',type=str,default='../Data/'+target ,help='data path')\n",
        "parser.add_argument('--adj_data_pre',type=str,default='../Data/'+target+'/adj_mat_input.pkl',help='adj data path')\n",
        "parser.add_argument('--num_nodes_pre',type=int,default=34,help='number of nodes/variables')\n",
        "parser.add_argument('--expid_pre',type=int,default=202308271352,help='experiment id')\n",
        "\n",
        "#------------------------------------------------------#\n",
        "\n",
        "parser.add_argument('--runs',type=int,default=3,help='number of runs')\n",
        "parser.add_argument('--epochs',type=int,default=180,help='')\n",
        "\n",
        "parser.add_argument('--seq_in_len',type=int,default=8,help='input sequence length')\n",
        "parser.add_argument('--seq_out_len',type=int,default=4,help='output sequence length')\n",
        "\n",
        "parser.add_argument('--layers',type=int,default=6,help='number of layers')\n",
        "\n",
        "parser.add_argument('--expid',type=int,default=202402230155,help='experiment id')\n",
        "\n",
        "\n",
        "#args = parser.parse_args()\n",
        "args=parser.parse_args(args=[])\n",
        "torch.set_num_threads(3)\n",
        "\n",
        "print('# args', args)\n",
        "\n",
        "device = torch.device(args.device)\n",
        "\n",
        "writer = SummaryWriter()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRD8IwnmANlj"
      },
      "source": [
        "### Loading Mobility Flows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUl-Eg70ANlj"
      },
      "outputs": [],
      "source": [
        "\n",
        "batch_size = args.batch_size\n",
        "valid_batch_size = args.batch_size\n",
        "test_batch_size = args.batch_size\n",
        "data = {}\n",
        "\n",
        "\n",
        "for category in ['train', 'val', 'test']:\n",
        "\n",
        "    # Loading npz\n",
        "    cat_data = np.load(os.path.join(args.data, category + '.npz'))\n",
        "\n",
        "    if args.log_print:\n",
        "        print(\"# Loading:\", category + '.npz')\n",
        "        for k in cat_data.files:\n",
        "            print(' - col:',k)\n",
        "\n",
        "    data['x_' + category] = cat_data['x']     # (?, 12, 207, 2)\n",
        "    data['y_' + category] = cat_data['y']     # (?, 12, 207, 2)\n",
        "\n",
        "    if args.log_print:\n",
        "        print(' - x_' +category +':', data['x_' + category].shape)\n",
        "        print(' - y_' +category +':', data['y_' + category].shape)\n",
        "\n",
        "\n",
        "# 使用train的mean/std來正規化valid/test #\n",
        "scaler = StandardScaler(mean=data['x_train'][..., 0].mean(), std=data['x_train'][..., 0].std())\n",
        "\n",
        "# 將欲訓練特徵改成正規化\n",
        "for category in ['train', 'val', 'test']:\n",
        "    data['x_' + category][..., 0] = scaler.transform(data['x_' + category][..., 0])\n",
        "\n",
        "\n",
        "data['train_loader'] = DataLoaderM(data['x_train'], data['y_train'], batch_size)\n",
        "data['val_loader'] = DataLoaderM(data['x_val'], data['y_val'], valid_batch_size)\n",
        "data['test_loader'] = DataLoaderM(data['x_test'], data['y_test'], test_batch_size)\n",
        "data['scaler'] = scaler\n",
        "\n",
        "sensor_ids, sensor_id_to_ind, adj_mx = load_adj(args.adj_data,args.adjtype)   # adjtype: default='doubletransition'\n",
        "\n",
        "adj_mx = [torch.tensor(i).to(device) for i in adj_mx]\n",
        "\n",
        "dataloader = data.copy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSXbT9A4n48l"
      },
      "source": [
        "### Loading  GCT Flows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnybVkKxn48m"
      },
      "outputs": [],
      "source": [
        "#**fusion**#\n",
        "batch_size = args.batch_size\n",
        "valid_batch_size = args.batch_size\n",
        "test_batch_size = args.batch_size\n",
        "data_pre = {}\n",
        "\n",
        "_types = ''\n",
        "\n",
        "for category in ['train'+_types, 'val'+_types, 'test'+_types]:\n",
        "\n",
        "    print(\"# Loading:\", category + '.npz')\n",
        "\n",
        "    # Loading npz\n",
        "    cat_data = np.load(os.path.join(args.data_pre, category + '.npz'))\n",
        "\n",
        "    data_pre['x_' + category] = cat_data['x']     # (?, 12, 207, 2)\n",
        "    data_pre['y_' + category] = cat_data['y']     # (?, 12, 207, 2)\n",
        "\n",
        "    print(cat_data['x'].shape)\n",
        "    print('x[0]:',cat_data['x'][0])\n",
        "    print('y[0]:',cat_data['y'][0])\n",
        "    print('x[-1]',cat_data['x'][-1])\n",
        "    print('y[-1]',cat_data['y'][-1])\n",
        "\n",
        "# 使用train的mean/std來正規化valid/test #\n",
        "scaler_pre = StandardScaler(mean=data_pre['x_train'+_types][..., 0].mean(), std=data_pre['x_train'+_types][..., 0].std())\n",
        "\n",
        "# 將欲訓練特徵改成正規化\n",
        "for category in ['train'+_types, 'val'+_types, 'test'+_types]:\n",
        "    data_pre['x_' + category][..., 0] = scaler_pre.transform(data_pre['x_' + category][..., 0])\n",
        "\n",
        "\n",
        "data_pre['train_loader'] = DataLoaderM(data_pre['x_train'+_types], data_pre['y_train'+_types], batch_size)\n",
        "data_pre['val_loader'] = DataLoaderM(data_pre['x_val'+_types], data_pre['y_val'+_types], valid_batch_size)\n",
        "data_pre['test_loader'] = DataLoaderM(data_pre['x_test'+_types], data_pre['y_test'+_types], test_batch_size)\n",
        "data_pre['scaler'] = scaler_pre\n",
        "\n",
        "sensor_ids_pre, sensor_id_to_ind_pre, adj_mx_pre = load_adj(args.adj_data_pre,args.adjtype)   # adjtype: default='doubletransition'\n",
        "\n",
        "adj_mx_pre = [torch.tensor(i).to(device) for i in adj_mx_pre]\n",
        "\n",
        "dataloader_pre = data_pre.copy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqCzbdDO0VVr"
      },
      "source": [
        "### Loading Neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHDv5cPdxB8D"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# load connections from csv\n",
        "df = pd.read_csv(os.path.join(args.data, 'neighbors_manual_v7_rename.csv'))\n",
        "connections = {}\n",
        "node_ids = set()  # Set to store unique node IDs\n",
        "for index, row in df.iterrows():\n",
        "    node = int(row['road_segment'])\n",
        "    neighbors = [int(x) for x in row[1:].dropna().tolist()]\n",
        "    connections[node] = neighbors\n",
        "    node_ids.add(node)\n",
        "    node_ids.update(neighbors)\n",
        "\n",
        "# Create a mapping from node IDs to indices\n",
        "mapping_dict = {node_id: index for index, node_id in enumerate(sorted(node_ids))}\n",
        "print(mapping_dict)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Apply the mapping to the 'road_segment' and neighbor columns\n",
        "for col in df.columns:\n",
        "    df[col] = df[col].map(mapping_dict)\n",
        "\n",
        "\n",
        "\n",
        "# Get the list of IDs\n",
        "ids = df['road_segment'].tolist()\n",
        "#print(len(ids))\n",
        "#sys.exit()\n",
        "\n",
        "# Initialize an adjacency matrix with zeros\n",
        "adj_edges = np.zeros((len(ids), len(ids)))\n",
        "\n",
        "# Populate the adjacency matrix based on the dataframe\n",
        "for index, row in df.iterrows():\n",
        "    node = row['road_segment']\n",
        "\n",
        "    for neighbor in row[1:]:\n",
        "        if np.isnan(neighbor):\n",
        "            continue\n",
        "        adj_edges[int(node), int(neighbor)] = 1\n",
        "\n",
        "for adj in adj_edges:\n",
        "    print(adj)\n",
        "\n",
        "\n",
        "#-----------------#\n",
        "\n",
        "#a = torch.rand((64,32,44,4))\n",
        "\n",
        "def get_outgoing_nodes(node, adj_matrix):\n",
        "    \"\"\"\n",
        "    Get the nodes that have a direct connection from the given node.\n",
        "\n",
        "    Parameters:\n",
        "    node (int): The index of the node.\n",
        "    adj_matrix (np.array): The adjacency matrix.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of nodes that connect from the given node.\n",
        "    \"\"\"\n",
        "    # Get the row corresponding to the node\n",
        "    row = adj_matrix[node, :]\n",
        "\n",
        "    # Get the indices of the elements that are 1\n",
        "    outgoing_nodes = np.where(row == 1)[0]\n",
        "\n",
        "    return outgoing_nodes.tolist()\n",
        "\n",
        "\n",
        "def get_index(idx, adj_matrix):\n",
        "    #target = a[:,:,2].unsqueeze(2)\n",
        "    #print(target[0,0])\n",
        "\n",
        "    # Get the nodes that connect from node 2\n",
        "    outgoing_nodes = get_outgoing_nodes(idx, adj_matrix)\n",
        "    '''\n",
        "    outgoing_nodes_representations = a[:,:,outgoing_nodes]\n",
        "    print('outgoing_nodes',outgoing_nodes)\n",
        "    print('outgoing_nodes_representations',outgoing_nodes_representations[0,0])\n",
        "    outgoing_mobility = outgoing_nodes_representations-target\n",
        "    print('outgoing_mobility',outgoing_mobility[0,0])\n",
        "    '''\n",
        "    # Get the nodes that connect to node 2\n",
        "    ingoing_nodes = get_outgoing_nodes(idx, adj_matrix.transpose(1,0))\n",
        "    '''\n",
        "    ingoing_nodes_representations = a[:,:,ingoing_nodes]\n",
        "    print('ingoing_nodes',ingoing_nodes)\n",
        "    print('ingoing_nodes_representations',ingoing_nodes_representations[0,0])\n",
        "    ingoing_mobility = target-ingoing_nodes_representations\n",
        "    print('ingoing_mobility',ingoing_mobility[0,0])\n",
        "    '''\n",
        "    return outgoing_nodes,ingoing_nodes\n",
        "\n",
        "outgoing = []\n",
        "ingoing = []\n",
        "for idx in range(len(adj_edges)):\n",
        "  out_nodes, in_nodes = get_index(idx, adj_edges)\n",
        "  outgoing.append(out_nodes)\n",
        "  ingoing.append(in_nodes)\n",
        "\n",
        "print('outgoing', outgoing)\n",
        "print('ingoing', ingoing)\n",
        "\n",
        "\n",
        "def get_node_name(index, node_dict):\n",
        "    # Create a reverse mapping from indices to node names\n",
        "    index_to_node = {v: k for k, v in node_dict.items()}\n",
        "    return index_to_node.get(index, \"Node index not found\")\n",
        "\n",
        "#node_mapping = {'1_to_3': 0, '2_to_3': 1, '3_to_1': 2, '3_to_2': 3, '3_to_4': 4, '4_to_3': 5, '4_to_5': 6, '5_to_4': 7, '5_to_6': 8, '6_to_5': 9, '6_to_7': 10, '7_to_6': 11, '7_to_8': 12, '8_to_7': 13, '8_to_13': 14, '8_to_14': 15, '9_to_10': 16, '9_to_12': 17, '10_to_9': 18, '10_to_41': 19, '12_to_9': 20, '12_to_13': 21, '12_to_37': 22, '13_to_12': 23, '13_to_14': 24, '13_to_21': 25, '14_to_8': 26, '14_to_13': 27, '14_to_20': 28, '16_to_17': 29, '16_to_18': 30, '16_to_19': 31, '17_to_12': 32, '17_to_16': 33, '17_to_25': 34, '17_to_37': 35, '18_to_16': 36, '18_to_19': 37, '19_to_16': 38, '19_to_18': 39, '19_to_20': 40, '20_to_14': 41, '20_to_19': 42, '20_to_23': 43, '21_to_13': 44, '21_to_17': 45, '21_to_20': 46, '21_to_23': 47, '23_to_20': 48, '23_to_21': 49, '23_to_25': 50, '23_to_26': 51, '24_to_26': 52, '25_to_17': 53, '25_to_23': 54, '25_to_27': 55, '26_to_23': 56, '26_to_24': 57, '26_to_28': 58, '27_to_25': 59, '27_to_28': 60, '27_to_29': 61, '28_to_26': 62, '28_to_27': 63, '28_to_30': 64, '29_to_27': 65, '29_to_30': 66, '29_to_36': 67, '30_to_28': 68, '30_to_29': 69, '30_to_31': 70, '30_to_35': 71, '31_to_30': 72, '31_to_32': 73, '31_to_34': 74, '32_to_31': 75, '32_to_40': 76, '34_to_31': 77, '34_to_35': 78, '34_to_41': 79, '35_to_30': 80, '35_to_34': 81, '35_to_38': 82, '36_to_29': 83, '36_to_37': 84, '37_to_12': 85, '37_to_17': 86, '37_to_36': 87, '37_to_38': 88, '38_to_35': 89, '38_to_37': 90, '38_to_41': 91, '40_to_32': 92, '40_to_41': 93, '40_to_42': 94, '41_to_10': 95, '41_to_34': 96, '41_to_38': 97, '41_to_40': 98, '41_to_45': 99, '42_to_40': 100, '42_to_43': 101, '43_to_42': 102, '43_to_44': 103, '43_to_46': 104, '44_to_43': 105, '45_to_37': 106, '45_to_41': 107, '45_to_46': 108, '46_to_43': 109, '46_to_45': 110, '46_to_47': 111, '47_to_46': 112, '47_to_48': 113, '47_to_49': 114, '48_to_47': 115, '48_to_49': 116, '49_to_47': 117, '49_to_48': 118}\n",
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(os.path.join(args.data, 'edges_id.csv'))\n",
        "\n",
        "# Extract the 'road_segment' column as a list\n",
        "edges = df['road_segment'].tolist()\n",
        "\n",
        "# Split the IDs by '_', convert to integers, and sort\n",
        "edges_sorted = sorted(edges, key=lambda x: [int(i) for i in x.split('_to_')])\n",
        "\n",
        "# Create a dictionary with IDs as keys and indices as values\n",
        "node_mapping = {edge: i for i, edge in enumerate(edges_sorted)}\n",
        "\n",
        "print(node_mapping, len(node_mapping.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHRzCzzHwNyc"
      },
      "source": [
        "### Trainer (pretrained model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoENJbLXwNyd"
      },
      "outputs": [],
      "source": [
        "\n",
        "#**fusion**#\n",
        "class Trainer_pretrained():\n",
        "    def __init__(self, model, lrate, wdecay, clip, step_size, seq_out_len, scaler, device, cl=True):\n",
        "        self.scaler = scaler\n",
        "\n",
        "        self.model = model\n",
        "        self.model.to(device)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=lrate, weight_decay=wdecay)\n",
        "        self.loss = masked_mae\n",
        "        self.clip = clip\n",
        "        self.step = step_size\n",
        "        self.iter = 1\n",
        "        self.task_level = 1\n",
        "        self.seq_out_len = seq_out_len\n",
        "        self.cl = cl\n",
        "\n",
        "\n",
        "    def eval(self, input, real_val):\n",
        "        #print('@Trainer_pretrained, input', input.shape)\n",
        "        #print('@Trainer_pretrained, real_val', real_val.shape)\n",
        "        self.model.eval()\n",
        "        output = self.model(input)\n",
        "        output = output.transpose(1,3)\n",
        "\n",
        "        #**fusion**#\n",
        "        output =   torch.cat([output,real_val[:,1,:output.size()[2]].unsqueeze(1)],dim=1)\n",
        "        #print('@Trainer_pretrained, output2', output.shape)\n",
        "        return output\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt-4u_AjxrJX"
      },
      "source": [
        "### Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8blhyFPOxrJX"
      },
      "outputs": [],
      "source": [
        "\n",
        "def main(runid):\n",
        "\n",
        "    # if args.load_static_feature:\n",
        "    #     static_feat = load_node_feature('data/sensor_graph/location.csv')\n",
        "    # else:\n",
        "    #     static_feat = None\n",
        "\n",
        "    model = gginet(args.model_type,\n",
        "                   args.num_nodes,\n",
        "                   device,\n",
        "                   predefined_A=adj_mx,\n",
        "\n",
        "                   dropout=args.dropout,  node_dim=args.node_dim, dilation_exponential=args.dilation_exponential, conv_channels=args.conv_channels, residual_channels=args.residual_channels,\n",
        "                  skip_channels=args.skip_channels, end_channels= args.end_channels,\n",
        "                  seq_length=args.seq_in_len, in_dim=args.in_dim, out_dim=args.seq_out_len,\n",
        "                  layers=args.layers, layer_norm_affline=True)\n",
        "    engine = Trainer(model, args.learning_rate, args.weight_decay, args.clip, args.step_size1, args.seq_out_len,\n",
        "                     data['scaler'], device, args.cl)\n",
        "\n",
        "\n",
        "    #**fusion**#\n",
        "    # 用mobility scaler試試看\n",
        "    model_pre = gginet(args.model_type,\n",
        "\n",
        "                   args.num_nodes_pre,\n",
        "                   device,\n",
        "                   predefined_A=adj_mx_pre,\n",
        "\n",
        "                   dropout=args.dropout, node_dim=args.node_dim, dilation_exponential=args.dilation_exponential, conv_channels=args.conv_channels, residual_channels=args.residual_channels,\n",
        "                  skip_channels=args.skip_channels, end_channels= args.end_channels,\n",
        "                  seq_length=args.seq_in_len, in_dim=args.in_dim, out_dim=args.seq_out_len,\n",
        "                  layers=args.layers, layer_norm_affline=True)\n",
        "\n",
        "    engine_pre = Trainer_pretrained(\n",
        "                      model_pre,\n",
        "                      args.learning_rate, args.weight_decay, args.clip, args.step_size1, args.seq_out_len,\n",
        "                      data['scaler'], device, args.cl)\n",
        "\n",
        "\n",
        "    #**fusion**#\n",
        "    # 載入model\n",
        "    SAVE_PATH = args.save + \"exp\" + str(args.expid_pre) + \"_3.pth\"\n",
        "    print(\"### loading model is:\",SAVE_PATH ,'###')\n",
        "    checkpoint = torch.load(SAVE_PATH)\n",
        "    engine_pre.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    engine_pre.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    loss = checkpoint['loss']\n",
        "\n",
        "    print(\"start training...\",flush=True)\n",
        "    his_loss =[]\n",
        "    val_time = []\n",
        "    train_time = []\n",
        "    minl = 1e5\n",
        "    start_epoch=0\n",
        "    SAVE_PATH = \"\"\n",
        "    train_loss_epoch = []  # 紀錄train在epoch收斂\n",
        "    valid_loss_epoch = []  # 紀錄valid在epoch收斂\n",
        "\n",
        "    for i in range(start_epoch,start_epoch+args.epochs+1):\n",
        "\n",
        "        train_loss = []\n",
        "        train_mape = []\n",
        "        train_rmse = []\n",
        "        train_smape = []\n",
        "        t1 = time.time()\n",
        "        #dataloader['train_loader'].shuffle()  # 為了檢視資料先拿掉\n",
        "        #**fusion**#\n",
        "        permutation = np.random.permutation(dataloader['train_loader'].size)\n",
        "        dataloader['train_loader'].set_permutation(permutation)\n",
        "        dataloader_pre['train_loader'].set_permutation(permutation)\n",
        "\n",
        "        #for iter, (x, y) in enumerate(dataloader['train_loader'].get_iterator()):\n",
        "        #**fusion**#\n",
        "        for iter, ((x, y), (x2, y2)) in enumerate(zip(dataloader['train_loader'].get_iterator(), dataloader_pre['train_loader'].get_iterator())):\n",
        "            trainx = torch.Tensor(x).to(device)\n",
        "            trainx= trainx.transpose(1, 3)\n",
        "            trainy = torch.Tensor(y).to(device)\n",
        "            trainy = trainy.transpose(1, 3)\n",
        "\n",
        "            #**fusion**#\n",
        "            trainx2 = torch.Tensor(x2).to(device)\n",
        "            trainx2= trainx2.transpose(1, 3)\n",
        "            trainy2 = torch.Tensor(y2).to(device)\n",
        "            trainy2 = trainy2.transpose(1, 3)\n",
        "\n",
        "            #print('x2', x2.shape)\n",
        "            #**fusion**#\n",
        "            # 要輸入完整trainy，因為要用到time\n",
        "            pre_trained_output = engine_pre.eval(trainx2,trainy2)\n",
        "            trainx = pre_trained_output\n",
        "\n",
        "            metrics = engine.train(trainx, trainy[:,0,:,:])\n",
        "\n",
        "            train_loss.append(metrics[0])\n",
        "            train_mape.append(metrics[1])\n",
        "            train_rmse.append(metrics[2])\n",
        "            train_smape.append(metrics[3])\n",
        "\n",
        "            #sys.exit()\n",
        "\n",
        "            if iter % args.print_every == 0 :\n",
        "                log = 'Iter: {:03d}, Train Loss: {:.4f}, Train MAPE: {:.4f}, Train RMSE: {:.4f}'\n",
        "                print(log.format(iter, train_loss[-1], train_mape[-1], train_rmse[-1]),flush=True)\n",
        "        t2 = time.time()\n",
        "        train_time.append(t2-t1)\n",
        "        #validation\n",
        "        valid_loss = []\n",
        "        valid_mape = []\n",
        "        valid_rmse = []\n",
        "        valid_smape = []\n",
        "\n",
        "        s1 = time.time()\n",
        "        #for iter, (x, y) in enumerate(dataloader['val_loader'].get_iterator()):\n",
        "        #**fusion**#\n",
        "        for iter, ((x, y), (x2, y2)) in enumerate(zip(dataloader['val_loader'].get_iterator(), dataloader_pre['val_loader'].get_iterator())):\n",
        "            testx = torch.Tensor(x).to(device)\n",
        "            testx = testx.transpose(1, 3)\n",
        "            testy = torch.Tensor(y).to(device)\n",
        "            testy = testy.transpose(1, 3)\n",
        "\n",
        "            #**fusion**#\n",
        "            testx2 = torch.Tensor(x2).to(device)\n",
        "            testx2= testx2.transpose(1, 3)\n",
        "            testy2 = torch.Tensor(y2).to(device)\n",
        "            testy2 = testy2.transpose(1, 3)\n",
        "\n",
        "            #**fusion**#\n",
        "            # 要輸入完整trainy，因為要用到time\n",
        "            pre_trained_output = engine_pre.eval(testx2,testy2)\n",
        "            testx = pre_trained_output\n",
        "\n",
        "\n",
        "            metrics = engine.eval(testx, testy[:,0,:,:])\n",
        "            valid_loss.append(metrics[0])\n",
        "            valid_mape.append(metrics[1])\n",
        "            valid_rmse.append(metrics[2])\n",
        "            valid_smape.append(metrics[3])\n",
        "        s2 = time.time()\n",
        "        log = 'Epoch: {:03d}, Inference Time: {:.4f} secs'\n",
        "        print(log.format(i,(s2-s1)))\n",
        "        val_time.append(s2-s1)\n",
        "        mtrain_loss = np.mean(train_loss)\n",
        "        mtrain_mape = np.mean(train_mape)\n",
        "        mtrain_rmse = np.mean(train_rmse)\n",
        "        mtrain_smape = np.mean(train_smape)\n",
        "\n",
        "        mvalid_loss = np.mean(valid_loss)\n",
        "        mvalid_mape = np.mean(valid_mape)\n",
        "        mvalid_rmse = np.mean(valid_rmse)\n",
        "        mvalid_smape = np.mean(valid_smape)\n",
        "        #his_loss.append(mvalid_loss)\n",
        "        his_loss.append(mvalid_smape)\n",
        "\n",
        "        #writer.add_scalar(\"train_loss\", mtrain_loss, i)\n",
        "        #writer.add_scalar(\"valid_loss\", mvalid_loss, i)\n",
        "\n",
        "        writer.add_scalar(\"train_loss\", mvalid_loss, i)\n",
        "        writer.add_scalar(\"valid_loss\", mvalid_loss, i)\n",
        "\n",
        "\n",
        "        log = 'Epoch: {:03d}, Train Loss: {:.4f}, Train MAPE: {:.4f}, Train RMSE: {:.4f}, Valid Loss: {:.4f}, Valid MAPE: {:.4f}, Valid RMSE: {:.4f}, Training Time: {:.4f}/epoch'\n",
        "        print(log.format(i, mtrain_loss, mtrain_mape, mtrain_rmse, mvalid_loss, mvalid_mape, mvalid_rmse, (t2 - t1)),flush=True)\n",
        "        # 紀錄每個epoch的loss\n",
        "        train_loss_epoch.append(mtrain_loss)\n",
        "        valid_loss_epoch.append(mvalid_loss)\n",
        "\n",
        "        '''\n",
        "        if mvalid_loss<minl:\n",
        "            torch.save(engine.model.state_dict(), args.save + \"exp\" + str(args.expid) + \"_\" + str(runid) +\".pth\")\n",
        "            minl = mvalid_loss\n",
        "        '''\n",
        "        if mvalid_loss<minl:\n",
        "            target_best_model = args.save + \"exp\" + str(args.expid) + \"_\" + str(runid) +\".pth\"\n",
        "            print(\"### Update Best Model:\",target_best_model, 'Loss:', mvalid_mape, \" ###\")\n",
        "            #torch.save(engine.model.state_dict(), args.save + \"exp\" + str(args.expid) + \"_\" + str(runid) +\".pth\")\n",
        "            SAVE_PATH = args.save + \"exp\" + str(args.expid) + \"_\" + str(runid) +\".pth\"\n",
        "            torch.save({\n",
        "              'epoch': i,\n",
        "              'task_level': engine.task_level,\n",
        "              'model_state_dict': engine.model.state_dict(),\n",
        "              'optimizer_state_dict': engine.optimizer.state_dict(),\n",
        "              'loss': mvalid_mape,\n",
        "              'train_loss': train_loss_epoch,\n",
        "              'valid_loss': valid_loss_epoch\n",
        "            }, SAVE_PATH)\n",
        "            minl = mvalid_loss\n",
        "\n",
        "    print(\"Average Training Time: {:.4f} secs/epoch\".format(np.mean(train_time)))\n",
        "    print(\"Average Inference Time: {:.4f} secs\".format(np.mean(val_time)))\n",
        "\n",
        "\n",
        "    bestid = np.argmin(his_loss)\n",
        "\n",
        "    writer.close()\n",
        "    print(\"Training finished\")\n",
        "    print(\"The valid loss on best model is\", str(round(his_loss[bestid],4)))\n",
        "\n",
        "    #target_model = args.save + \"exp\" + str(args.expid) + \"_\" + str(runid) +\".pth\"\n",
        "    SAVE_PATH = args.save + \"exp\" + str(args.expid) + \"_\" + str(runid) +\".pth\"\n",
        "    print(\"### loading model is:\",SAVE_PATH ,'###')\n",
        "    #engine.model.load_state_dict(torch.load(args.save + \"exp\" + str(args.expid) + \"_\" + str(runid) +\".pth\"))\n",
        "    checkpoint = torch.load(SAVE_PATH)\n",
        "    engine.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    engine.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    loss = checkpoint['loss']\n",
        "    print(\"### Loading Model finished ###\")\n",
        "    print(\"### The valid loss on loding model is\", str(round(loss,4)))\n",
        "\n",
        "    # 只更新最後的train loss\n",
        "    #checkpoint['train_loss'] = train_loss_epoch\n",
        "    #checkpoint['valid_loss'] = valid_loss_epoch\n",
        "    torch.save({\n",
        "      'epoch': checkpoint['epoch'],  # best epoch\n",
        "      'task_level': checkpoint['task_level'],\n",
        "      'model_state_dict': checkpoint['model_state_dict'],\n",
        "      'optimizer_state_dict': checkpoint['optimizer_state_dict'],\n",
        "      'loss': checkpoint['loss'],\n",
        "      'train_loss': checkpoint['train_loss'],\n",
        "      'valid_loss': checkpoint['valid_loss']\n",
        "    }, SAVE_PATH)\n",
        "    ### 測試讀取出的model ###\n",
        "    valid_loss = []\n",
        "    valid_mape = []\n",
        "    valid_rmse = []\n",
        "    valid_smape = []\n",
        "    s1 = time.time()\n",
        "    #for iter, (x, y) in enumerate(dataloader['val_loader'].get_iterator()):\n",
        "    #**fusion**#\n",
        "    for iter, ((x, y), (x2, y2)) in enumerate(zip(dataloader['val_loader'].get_iterator(), dataloader_pre['val_loader'].get_iterator())):\n",
        "        testx = torch.Tensor(x).to(device)\n",
        "        testx = testx.transpose(1, 3)\n",
        "        testy = torch.Tensor(y).to(device)\n",
        "        testy = testy.transpose(1, 3)\n",
        "\n",
        "        #**fusion**#\n",
        "        testx2 = torch.Tensor(x2).to(device)\n",
        "        testx2= testx2.transpose(1, 3)\n",
        "        testy2 = torch.Tensor(y2).to(device)\n",
        "        testy2 = testy2.transpose(1, 3)\n",
        "\n",
        "        #**fusion**#\n",
        "        # 要輸入完整trainy，因為要用到time\n",
        "        pre_trained_output = engine_pre.eval(testx2,testy2)\n",
        "        testx = pre_trained_output\n",
        "\n",
        "        metrics = engine.eval(testx, testy[:,0,:,:])\n",
        "        valid_loss.append(metrics[0])\n",
        "        valid_mape.append(metrics[1])\n",
        "        valid_rmse.append(metrics[2])\n",
        "        valid_smape.append(metrics[3])\n",
        "\n",
        "    mvalid_loss = np.mean(valid_loss)\n",
        "    mvalid_mape = np.mean(valid_mape)\n",
        "    mvalid_rmse = np.mean(valid_rmse)\n",
        "    print(\"### 2-The valid loss on loding model is\", str(round(mvalid_mape,4)))\n",
        "    ### 測試讀取出的model ###\n",
        "\n",
        "    #valid data\n",
        "    outputs = []\n",
        "    realy = torch.Tensor(dataloader['y_val']).to(device)\n",
        "    realy = realy.transpose(1,3)[:,0,:,:]\n",
        "    print('#realy', realy.shape)\n",
        "\n",
        "    #for iter, (x, y) in enumerate(dataloader['val_loader'].get_iterator()):\n",
        "    #**fusion**#\n",
        "    for iter, ((x, y), (x2, y2)) in enumerate(zip(dataloader['val_loader'].get_iterator(), dataloader_pre['val_loader'].get_iterator())):\n",
        "        testx = torch.Tensor(x).to(device)\n",
        "        testx = testx.transpose(1,3)\n",
        "        testy = torch.Tensor(y).to(device)\n",
        "        testy = testy.transpose(1, 3)\n",
        "\n",
        "        #**fusion**#\n",
        "        testx2 = torch.Tensor(x2).to(device)\n",
        "        testx2= testx2.transpose(1, 3)\n",
        "        testy2 = torch.Tensor(y2).to(device)\n",
        "        testy2 = testy2.transpose(1, 3)\n",
        "\n",
        "        #**fusion**#\n",
        "        # 要輸入完整trainy，因為要用到time\n",
        "        pre_trained_output = engine_pre.eval(testx2,testy2)\n",
        "        testx = pre_trained_output\n",
        "\n",
        "\n",
        "        #print('testx2', testx.shape)\n",
        "        with torch.no_grad():\n",
        "            preds = engine.model(testx)\n",
        "            preds = preds.transpose(1,3)  # 64,1,6,12\n",
        "\n",
        "        outputs.append(preds.squeeze()) # 64,1,6,12 ->squeeze()->64,6,12\n",
        "\n",
        "    yhat = torch.cat(outputs,dim=0)\n",
        "    yhat = yhat[:realy.size(0),...]  # 5240,6,12\n",
        "    print('# cat valid preds', yhat.shape)\n",
        "\n",
        "    pred = data['scaler'].inverse_transform(yhat)\n",
        "\n",
        "    vmae, vmape, vrmse,vsmape = metric(pred,realy)\n",
        "    print(\"valid mape\",vmape)\n",
        "\n",
        "    #test data\n",
        "    outputs = []\n",
        "    realy = torch.Tensor(dataloader['y_test']).to(device)\n",
        "    realy = realy.transpose(1, 3)[:, 0, :, :]\n",
        "\n",
        "    #for iter, (x, y) in enumerate(dataloader['test_loader'].get_iterator()):\n",
        "    #**fusion**#\n",
        "    for iter, ((x, y), (x2, y2)) in enumerate(zip(dataloader['test_loader'].get_iterator(), dataloader_pre['test_loader'].get_iterator())):\n",
        "        testx = torch.Tensor(x).to(device)\n",
        "        testx = testx.transpose(1, 3)\n",
        "\n",
        "\n",
        "        #**fusion**#\n",
        "        testx2 = torch.Tensor(x2).to(device)\n",
        "        testx2= testx2.transpose(1, 3)\n",
        "        testy2 = torch.Tensor(y2).to(device)\n",
        "        testy2 = testy2.transpose(1, 3)\n",
        "\n",
        "        #**fusion**#\n",
        "        # 要輸入完整trainy，因為要用到time\n",
        "        pre_trained_output = engine_pre.eval(testx2,testy2)\n",
        "        testx = pre_trained_output\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = engine.model(testx)\n",
        "            preds = preds.transpose(1, 3)\n",
        "        outputs.append(preds.squeeze())\n",
        "\n",
        "    yhat = torch.cat(outputs, dim=0)\n",
        "    yhat = yhat[:realy.size(0), ...]  #10478, 6, 12\n",
        "    print('# cat test preds', yhat.shape)\n",
        "\n",
        "    mae = []\n",
        "    mape = []\n",
        "    rmse = []\n",
        "    smape = []\n",
        "    for i in range(args.seq_out_len):\n",
        "\n",
        "        pred = data['scaler'].inverse_transform(yhat[:, :, i])\n",
        "\n",
        "        real = realy[:, :, i]\n",
        "\n",
        "        metrics = metric(pred, real)\n",
        "\n",
        "        log = 'Evaluate best model on test data for horizon {:d}, Test MAE: {:.4f}, Test MAPE: {:.4f}, Test RMSE: {:.4f}'\n",
        "        print(log.format(i + 1, metrics[0], metrics[1], metrics[2]))\n",
        "        mae.append(metrics[0])\n",
        "        mape.append(metrics[1])\n",
        "        rmse.append(metrics[2])\n",
        "        smape.append(metrics[3])\n",
        "\n",
        "    log = '{:.2f}\t{:.2f}\t{:.4f}\t{:.4f}\t'\n",
        "    print( \"##### exp\" + str(args.expid) + \"_\" + str(runid)+'\t',\n",
        "          log.format(mae[0], rmse[0], smape[0], mape[0]),\n",
        "          log.format(mae[1], rmse[1], smape[1], mape[1]),\n",
        "          log.format(mae[2], rmse[2], smape[2], mape[2]),\n",
        "          log.format(mae[3], rmse[3], smape[3], mape[3]),\n",
        "         )\n",
        "\n",
        "    ### Drawing Loss Diagram ###\n",
        "    fig = plt.figure(figsize=(10, 6), dpi=600)\n",
        "    plt.plot(checkpoint['train_loss'], label=\"train loss\")\n",
        "    plt.plot(checkpoint['valid_loss'], label=\"valid loss\")\n",
        "    plt.legend(loc=\"upper right\")\n",
        "    plt.title('#Loss of Training', fontsize=20)\n",
        "    plt.ylabel(\"MAPE\", fontsize=14)\n",
        "    plt.xlabel(\"Epochs\", fontsize=14)\n",
        "    plt.show()\n",
        "\n",
        "    return vmae, vmape, vrmse,vsmape, mae, mape, rmse,smape\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    vmae = []\n",
        "    vmape = []\n",
        "    vrmse = []\n",
        "    vsmape = []\n",
        "    mae = []\n",
        "    mape = []\n",
        "    rmse = []\n",
        "    smape = []\n",
        "    for i in range(args.runs):\n",
        "        vm1, vm2, vm3,vm4, m1, m2, m3, m4 = main(i)\n",
        "        vmae.append(vm1)\n",
        "        vmape.append(vm2)\n",
        "        vrmse.append(vm3)\n",
        "        vsmape.append(vm4)\n",
        "        mae.append(m1)\n",
        "        mape.append(m2)\n",
        "        rmse.append(m3)\n",
        "        smape.append(m4)\n",
        "\n",
        "    mae = np.array(mae)\n",
        "    mape = np.array(mape)\n",
        "    rmse = np.array(rmse)\n",
        "    smape = np.array(smape)\n",
        "\n",
        "    amae = np.mean(mae,0)\n",
        "    amape = np.mean(mape,0)\n",
        "    armse = np.mean(rmse,0)\n",
        "    asmape = np.mean(smape,0)\n",
        "\n",
        "    smae = np.std(mae,0)\n",
        "    s_mape = np.std(mape,0)\n",
        "    srmse = np.std(rmse,0)\n",
        "    s_smape = np.std(smape,0)\n",
        "\n",
        "    print('\\n\\nResults for 10 runs\\n\\n')\n",
        "    #valid data\n",
        "    print('valid\\tMAE\\tRMSE\\tMAPE')\n",
        "    log = 'mean:\\t{:.4f}\\t{:.4f}\\t{:.4f}'\n",
        "    print(log.format(np.mean(vmae),np.mean(vrmse),np.mean(vmape)))\n",
        "    log = 'std:\\t{:.4f}\\t{:.4f}\\t{:.4f}'\n",
        "    print(log.format(np.std(vmae),np.std(vrmse),np.std(vmape)))\n",
        "    print('\\n\\n')\n",
        "    #test data\n",
        "    print('test|horizon\\tMAE-mean\\tRMSE-mean\\tMAPE-mean\\tMAE-std\\tRMSE-std\\tMAPE-std')\n",
        "    for i in [0,1,2,3]:\n",
        "        log = '{:d}\\t{:.4f}\\t{:.4f}\\t{:.4f}\\t{:.4f}\\t{:.4f}\\t{:.4f}'\n",
        "        print(log.format(i+1, amae[i], armse[i], amape[i], smae[i], srmse[i], s_mape[i]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59_z6s6hgydY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}